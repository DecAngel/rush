{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python391jvsc74a57bd01cf78cca13970d80a338afa68b61a5f69aebb270b5c839e5bacde3a2a105ceb4",
   "display_name": "Python 3.9.1 64-bit ('pytorch17': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Import modules"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "from collections import OrderedDict\n",
    "import copy\n",
    "import random\n",
    "import glob\n",
    "from easydict import EasyDict\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torch.nn.init as init\n",
    "import torch.utils.data as data\n",
    "import torch.utils.data.dataset as dataset\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import torchvision.utils as v_utils\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from models.MNAD.model.utils import CustomDataLoader\n",
    "from models.MNAD.model.final_future_prediction_with_memory_spatial_sumonly_weight_ranking_top1 import *\n",
    "from models.MNAD.model.Reconstruction import *\n",
    "from models.MNAD.utils import *\n",
    "import urls"
   ]
  },
  {
   "source": [
    "## 1 Set configs and environment"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = EasyDict(\n",
    "    # dataset\n",
    "    video_folder='/home/yuanyu/projects/data/DaYanTa_2/8_C51/frames',\n",
    "    label_file_path='/home/yuanyu/projects/dyt_VAD/label.csv',\n",
    "    transform=transforms.Compose([transforms.ToTensor()]),\n",
    "    resized_height=256,\n",
    "    resized_width=256,\n",
    "    time_step=4,\n",
    "    num_pred=1,\n",
    "\n",
    "    # model\n",
    "    method='pred',\n",
    "    t_length=5,\n",
    "    fdim=512,\n",
    "    mdim=512,\n",
    "    msize=10,\n",
    "\n",
    "    # test\n",
    "    alpha=1,\n",
    "    th=0.01,\n",
    "    num_workers=1,\n",
    "    model_path='./models/MNAD/exp/Xian/pred/log/model.pth',\n",
    "    m_items_path='./models/MNAD/exp/Xian/pred/log/keys.pt',\n",
    "    loss_func_mse=nn.MSELoss(reduction='none'),\n",
    "    gpus='1,2,3',\n",
    "    batch_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = cfg.gpus\n",
    "# make sure to use cudnn for computational performance\n",
    "torch.backends.cudnn.enabled = True"
   ]
  },
  {
   "source": [
    "## 2 Load the dataset and model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init dataloader\n",
    "test_dataset = CustomDataLoader(cfg.video_folder, transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "]), label_file_path=cfg.label_file_path,\n",
    "    resize_height=cfg.resized_height, resize_width=cfg.resized_width, time_step=cfg.t_length-1, train=False)\n",
    "\n",
    "test_loader = data.DataLoader(test_dataset, batch_size=cfg.batch_size,\n",
    "                             shuffle=False, num_workers=cfg.num_workers, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init model\n",
    "model = torch.load(cfg.model_path)\n",
    "model.cuda()\n",
    "model.eval()\n",
    "m_items = torch.load(cfg.m_items_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log and test data_loader\n",
    "print(len(test_loader))\n",
    "for data in test_loader:\n",
    "    print(type(data), data.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log and test model\n",
    "for imgs in test_loader:\n",
    "    imgs = imgs.cuda()\n",
    "    outputs, feas, updated_feas, m_items, softmax_score_query, softmax_score_memory, _, _, _, compactness_loss = model.forward(\n",
    "        imgs[:, 0:3*4], m_items, False\n",
    "    )\n",
    "    mse_imgs = cfg.loss_func_mse((outputs[0]+1)/2, (imgs[0, 3*4:]+1)/2)\n",
    "    mse_loss = torch.mean(mse_imgs).item()\n",
    "    mse_feas = compactness_loss.item()\n",
    "    \n",
    "    print(mse_loss)\n",
    "    break"
   ]
  },
  {
   "source": [
    "## 3 Run the model on dataloader, and save results"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init result savers\n",
    "results = dict()\n",
    "\n",
    "video_name_list = list()\n",
    "\n",
    "mse_imgs_list = list()\n",
    "mse_loss_list = list()\n",
    "psnr_list = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for imgs in test_loader:\n",
    "    imgs = imgs.cuda()\n",
    "    outputs, feas, updated_feas, m_items, softmax_score_query, softmax_score_memory, _, _, _, compactness_loss = model.forward(\n",
    "        imgs[:, 0:3*4], m_items, False\n",
    "    )\n",
    "    mse_imgs = cfg.loss_func_mse((outputs[0]+1)/2, (imgs[0, 3*4:]+1)/2)\n",
    "    mse_loss = torch.mean(mse_imgs).item()\n",
    "    mse_feas = compactness_loss.item()\n",
    "    psnr_ = psnr(mse_loss)\n",
    "\n",
    "    # print(mse_loss)\n",
    "    mse_imgs_list.append(mse_imgs)\n",
    "    mse_loss_list.append(mse_loss)\n",
    "    psnr_list.append(psnr_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}